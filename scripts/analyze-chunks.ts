#!/usr/bin/env node

/**
 * Script para analisar a qualidade dos chunks processados
 */

import { config } from "dotenv";
config({ path: ".env.local" });

import { createClient } from "@supabase/supabase-js";

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseServiceKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;

async function analyzeChunks() {
  console.log("üîç Analisando qualidade dos chunks...\n");

  if (!supabaseUrl || !supabaseServiceKey) {
    console.error("‚ùå Vari√°veis de ambiente n√£o encontradas");
    return;
  }

  const supabase = createClient(supabaseUrl, supabaseServiceKey);

  try {
    // 1. Contar total de chunks
    const { count: totalChunks } = await supabase
      .from("curriculum_chunks")
      .select("*", { count: "exact", head: true });

    console.log(`üìä Total de chunks: ${totalChunks}`);

    // 2. Contar por documento
    const { data: documents } = await supabase
      .from("curriculum_chunks")
      .select("document_name")
      .order("document_name");

    const docCounts = documents?.reduce((acc: Record<string, number>, doc) => {
      acc[doc.document_name] = (acc[doc.document_name] || 0) + 1;
      return acc;
    }, {});

    console.log("\nüìÅ Chunks por documento:");
    Object.entries(docCounts || {}).forEach(([doc, count]) => {
      console.log(`   ${doc}: ${count} chunks`);
    });

    // 3. Mostrar amostras de chunks
    console.log("\nüìù Amostras de chunks (primeiros 3 de cada documento):");

    const uniqueDocs = [
      ...new Set(documents?.map((d) => d.document_name) || []),
    ];

    for (const docName of uniqueDocs) {
      console.log(`\n--- ${docName} ---`);

      const { data: samples } = await supabase
        .from("curriculum_chunks")
        .select("content")
        .eq("document_name", docName)
        .limit(3);

      samples?.forEach((sample, index) => {
        console.log(`\nChunk ${index + 1}:`);
        console.log(`Tamanho: ${sample.content.length} caracteres`);
        console.log(`Preview: ${sample.content.substring(0, 200)}...`);
        console.log("---");
      });
    }

    // 4. Verificar chunks muito pequenos ou muito grandes
    console.log("\n‚ö†Ô∏è An√°lise de qualidade:");

    const { data: allChunks } = await supabase
      .from("curriculum_chunks")
      .select("content, document_name");

    if (allChunks) {
      const sizes = allChunks.map((chunk) => chunk.content.length);
      const avgSize = sizes.reduce((a, b) => a + b, 0) / sizes.length;
      const minSize = Math.min(...sizes);
      const maxSize = Math.max(...sizes);

      console.log(`   Tamanho m√©dio: ${Math.round(avgSize)} caracteres`);
      console.log(`   Menor chunk: ${minSize} caracteres`);
      console.log(`   Maior chunk: ${maxSize} caracteres`);

      const smallChunks = allChunks.filter(
        (chunk) => chunk.content.length < 100
      );
      const largeChunks = allChunks.filter(
        (chunk) => chunk.content.length > 2000
      );

      if (smallChunks.length > 0) {
        console.log(
          `   ‚ö†Ô∏è ${smallChunks.length} chunks muito pequenos (< 100 chars)`
        );
      }
      if (largeChunks.length > 0) {
        console.log(
          `   ‚ö†Ô∏è ${largeChunks.length} chunks muito grandes (> 2000 chars)`
        );
      }
    }

    // 5. Testar busca sem√¢ntica
    console.log("\nüß™ Teste de busca sem√¢ntica:");

    const testQueries = [
      "adi√ß√£o e subtra√ß√£o",
      "leitura e escrita",
      "geometria",
      "gram√°tica",
    ];

    for (const query of testQueries) {
      console.log(`\nPergunta: "${query}"`);

      // Simular busca (sem gerar embedding real)
      const { data: matches } = await supabase
        .from("curriculum_chunks")
        .select("content, document_name")
        .or(`content.ilike.%${query}%`)
        .limit(2);

      if (matches && matches.length > 0) {
        console.log(`   Encontrados: ${matches.length} chunks`);
        matches.forEach((match, i) => {
          console.log(
            `   ${i + 1}. ${match.document_name}: ${match.content.substring(
              0,
              100
            )}...`
          );
        });
      } else {
        console.log("   Nenhum resultado encontrado");
      }
    }
  } catch (error) {
    console.error("‚ùå Erro ao analisar chunks:", error);
  }
}

analyzeChunks();
